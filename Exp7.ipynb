{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a8b69f-c8bd-4aa1-b591-fb2fb7fa6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcda42e7-06a7-49ca-9f2c-1d5b9b215190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede3fc68-55cd-438e-94ac-8afdf807cf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\averaged_perceptron_tagger_rus.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\dolch.zip.\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\english_wordnet.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker_tab.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\maxent_treebank_pos_tagger_tab.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping help\\tagsets.zip.\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping help\\tagsets_json.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\varad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd26a61e-3d78-4c51-b823-647ad138007e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='sample.txt.txt' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('sample.txt.txt', 'r')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1a3c74-b4e9-4813-afde-4f88868981a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sun dipped below the horizon, casting a golden hue across the silent valley. A gentle breeze rustled the tall grass, whispering secrets of the day gone by. In the distance, an owl hooted, its call echoing through the twilight. Beneath the fading sky, a fox trotted along a narrow path, pausing briefly to sniff the air before disappearing into the woods. Time seemed to slow, holding its breath as night unfolded its velvet canopy overhead.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = file.read()\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165ff51b-9b97-41dd-b0b2-2b546f0d6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02b8b93-c99d-46ef-b513-a7dbaf1f0d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The sun dipped below the horizon, casting a golden hue across the silent valley.',\n",
       " 'A gentle breeze rustled the tall grass, whispering secrets of the day gone by.',\n",
       " 'In the distance, an owl hooted, its call echoing through the twilight.',\n",
       " 'Beneath the fading sky, a fox trotted along a narrow path, pausing briefly to sniff the air before disappearing into the woods.',\n",
       " 'Time seemed to slow, holding its breath as night unfolded its velvet canopy overhead.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = sent_tokenize(content)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f862cc35-4262-4616-9bf5-fc0373ccd513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'sun',\n",
       " 'dipped',\n",
       " 'below',\n",
       " 'the',\n",
       " 'horizon',\n",
       " ',',\n",
       " 'casting',\n",
       " 'a',\n",
       " 'golden',\n",
       " 'hue',\n",
       " 'across',\n",
       " 'the',\n",
       " 'silent',\n",
       " 'valley',\n",
       " '.',\n",
       " 'A',\n",
       " 'gentle',\n",
       " 'breeze',\n",
       " 'rustled',\n",
       " 'the',\n",
       " 'tall',\n",
       " 'grass',\n",
       " ',',\n",
       " 'whispering',\n",
       " 'secrets',\n",
       " 'of',\n",
       " 'the',\n",
       " 'day',\n",
       " 'gone',\n",
       " 'by',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'distance',\n",
       " ',',\n",
       " 'an',\n",
       " 'owl',\n",
       " 'hooted',\n",
       " ',',\n",
       " 'its',\n",
       " 'call',\n",
       " 'echoing',\n",
       " 'through',\n",
       " 'the',\n",
       " 'twilight',\n",
       " '.',\n",
       " 'Beneath',\n",
       " 'the',\n",
       " 'fading',\n",
       " 'sky',\n",
       " ',',\n",
       " 'a',\n",
       " 'fox',\n",
       " 'trotted',\n",
       " 'along',\n",
       " 'a',\n",
       " 'narrow',\n",
       " 'path',\n",
       " ',',\n",
       " 'pausing',\n",
       " 'briefly',\n",
       " 'to',\n",
       " 'sniff',\n",
       " 'the',\n",
       " 'air',\n",
       " 'before',\n",
       " 'disappearing',\n",
       " 'into',\n",
       " 'the',\n",
       " 'woods',\n",
       " '.',\n",
       " 'Time',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'slow',\n",
       " ',',\n",
       " 'holding',\n",
       " 'its',\n",
       " 'breath',\n",
       " 'as',\n",
       " 'night',\n",
       " 'unfolded',\n",
       " 'its',\n",
       " 'velvet',\n",
       " 'canopy',\n",
       " 'overhead',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "Words = word_tokenize(content)\n",
    "Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f63e1e49-986a-44c5-bad9-aea230fa0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad99237-b392-4206-9129-9932b356a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed54045d-2558-44e8-a6b8-a54978524f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1023189d-3ea3-4ece-bd2e-cea0234c2e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words without stopWords ['sun', 'dipped', 'horizon', ',', 'casting', 'golden', 'hue', 'across', 'silent', 'valley', '.']\n",
      "Words with stopwords ['The', 'sun', 'dipped', 'below', 'the', 'horizon', ',', 'casting', 'a', 'golden', 'hue', 'across', 'the', 'silent', 'valley', '.']\n",
      "POS tagging [('sun', 'NN'), ('dipped', 'VBD'), ('horizon', 'NN'), (',', ','), ('casting', 'VBG'), ('golden', 'JJ'), ('hue', 'NN'), ('across', 'IN'), ('silent', 'JJ'), ('valley', 'NN'), ('.', '.')]\n",
      "Words without stopWords ['gentle', 'breeze', 'rustled', 'tall', 'grass', ',', 'whispering', 'secrets', 'day', 'gone', '.']\n",
      "Words with stopwords ['A', 'gentle', 'breeze', 'rustled', 'the', 'tall', 'grass', ',', 'whispering', 'secrets', 'of', 'the', 'day', 'gone', 'by', '.']\n",
      "POS tagging [('gentle', 'JJ'), ('breeze', 'NN'), ('rustled', 'VBD'), ('tall', 'JJ'), ('grass', 'NN'), (',', ','), ('whispering', 'VBG'), ('secrets', 'NNS'), ('day', 'NN'), ('gone', 'VBN'), ('.', '.')]\n",
      "Words without stopWords ['distance', ',', 'owl', 'hooted', ',', 'call', 'echoing', 'twilight', '.']\n",
      "Words with stopwords ['In', 'the', 'distance', ',', 'an', 'owl', 'hooted', ',', 'its', 'call', 'echoing', 'through', 'the', 'twilight', '.']\n",
      "POS tagging [('distance', 'NN'), (',', ','), ('owl', 'NN'), ('hooted', 'VBD'), (',', ','), ('call', 'VB'), ('echoing', 'VBG'), ('twilight', 'NN'), ('.', '.')]\n",
      "Words without stopWords ['beneath', 'fading', 'sky', ',', 'fox', 'trotted', 'along', 'narrow', 'path', ',', 'pausing', 'briefly', 'sniff', 'air', 'disappearing', 'woods', '.']\n",
      "Words with stopwords ['Beneath', 'the', 'fading', 'sky', ',', 'a', 'fox', 'trotted', 'along', 'a', 'narrow', 'path', ',', 'pausing', 'briefly', 'to', 'sniff', 'the', 'air', 'before', 'disappearing', 'into', 'the', 'woods', '.']\n",
      "POS tagging [('beneath', 'NN'), ('fading', 'NN'), ('sky', 'NN'), (',', ','), ('fox', 'RB'), ('trotted', 'VBN'), ('along', 'IN'), ('narrow', 'JJ'), ('path', 'NN'), (',', ','), ('pausing', 'VBG'), ('briefly', 'NN'), ('sniff', 'VBD'), ('air', 'NN'), ('disappearing', 'VBG'), ('woods', 'NNS'), ('.', '.')]\n",
      "Words without stopWords ['time', 'seemed', 'slow', ',', 'holding', 'breath', 'night', 'unfolded', 'velvet', 'canopy', 'overhead', '.']\n",
      "Words with stopwords ['Time', 'seemed', 'to', 'slow', ',', 'holding', 'its', 'breath', 'as', 'night', 'unfolded', 'its', 'velvet', 'canopy', 'overhead', '.']\n",
      "POS tagging [('time', 'NN'), ('seemed', 'VBD'), ('slow', 'JJ'), (',', ','), ('holding', 'VBG'), ('breath', 'NN'), ('night', 'NN'), ('unfolded', 'VBD'), ('velvet', 'NN'), ('canopy', 'NN'), ('overhead', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for sen in sentence:\n",
    "    Words = word_tokenize(sen)\n",
    "    filteredWords = [word.lower() for word in Words if word.lower() not in stopWords]\n",
    "    print(f\"Words without stopWords {filteredWords}\")\n",
    "    print(f\"Words with stopwords {Words}\")\n",
    "    print(f\"POS tagging {nltk.pos_tag(filteredWords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a27fed6-ace0-4a21-8268-1e0723f13c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging [('time', 'NN'), ('seemed', 'VBD'), ('slow', 'JJ'), (',', ','), ('holding', 'VBG'), ('breath', 'NN'), ('night', 'NN'), ('unfolded', 'VBD'), ('velvet', 'NN'), ('canopy', 'NN'), ('overhead', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"POS tagging {nltk.pos_tag(filteredWords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11f5da9d-dc5d-43fe-b5d0-499edb33cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d30bfdd4-3f22-4efe-9efd-cfe1d6ecda16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The = After Stemming - the\n",
      "sun = After Stemming - sun\n",
      "dipped = After Stemming - dip\n",
      "below = After Stemming - below\n",
      "the = After Stemming - the\n",
      "horizon = After Stemming - horizon\n",
      ", = After Stemming - ,\n",
      "casting = After Stemming - cast\n",
      "a = After Stemming - a\n",
      "golden = After Stemming - golden\n",
      "hue = After Stemming - hue\n",
      "across = After Stemming - across\n",
      "the = After Stemming - the\n",
      "silent = After Stemming - silent\n",
      "valley = After Stemming - valley\n",
      ". = After Stemming - .\n",
      "A = After Stemming - a\n",
      "gentle = After Stemming - gentl\n",
      "breeze = After Stemming - breez\n",
      "rustled = After Stemming - rustl\n",
      "the = After Stemming - the\n",
      "tall = After Stemming - tall\n",
      "grass = After Stemming - grass\n",
      ", = After Stemming - ,\n",
      "whispering = After Stemming - whisper\n",
      "secrets = After Stemming - secret\n",
      "of = After Stemming - of\n",
      "the = After Stemming - the\n",
      "day = After Stemming - day\n",
      "gone = After Stemming - gone\n",
      "by = After Stemming - by\n",
      ". = After Stemming - .\n",
      "In = After Stemming - in\n",
      "the = After Stemming - the\n",
      "distance = After Stemming - distanc\n",
      ", = After Stemming - ,\n",
      "an = After Stemming - an\n",
      "owl = After Stemming - owl\n",
      "hooted = After Stemming - hoot\n",
      ", = After Stemming - ,\n",
      "its = After Stemming - it\n",
      "call = After Stemming - call\n",
      "echoing = After Stemming - echo\n",
      "through = After Stemming - through\n",
      "the = After Stemming - the\n",
      "twilight = After Stemming - twilight\n",
      ". = After Stemming - .\n",
      "Beneath = After Stemming - beneath\n",
      "the = After Stemming - the\n",
      "fading = After Stemming - fade\n",
      "sky = After Stemming - sky\n",
      ", = After Stemming - ,\n",
      "a = After Stemming - a\n",
      "fox = After Stemming - fox\n",
      "trotted = After Stemming - trot\n",
      "along = After Stemming - along\n",
      "a = After Stemming - a\n",
      "narrow = After Stemming - narrow\n",
      "path = After Stemming - path\n",
      ", = After Stemming - ,\n",
      "pausing = After Stemming - paus\n",
      "briefly = After Stemming - briefli\n",
      "to = After Stemming - to\n",
      "sniff = After Stemming - sniff\n",
      "the = After Stemming - the\n",
      "air = After Stemming - air\n",
      "before = After Stemming - befor\n",
      "disappearing = After Stemming - disappear\n",
      "into = After Stemming - into\n",
      "the = After Stemming - the\n",
      "woods = After Stemming - wood\n",
      ". = After Stemming - .\n",
      "Time = After Stemming - time\n",
      "seemed = After Stemming - seem\n",
      "to = After Stemming - to\n",
      "slow = After Stemming - slow\n",
      ", = After Stemming - ,\n",
      "holding = After Stemming - hold\n",
      "its = After Stemming - it\n",
      "breath = After Stemming - breath\n",
      "as = After Stemming - as\n",
      "night = After Stemming - night\n",
      "unfolded = After Stemming - unfold\n",
      "its = After Stemming - it\n",
      "velvet = After Stemming - velvet\n",
      "canopy = After Stemming - canopi\n",
      "overhead = After Stemming - overhead\n",
      ". = After Stemming - .\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "for word in Words:\n",
    "    print(f\"{word} = After Stemming - {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e0f97b5-a697-48c5-b8ea-a30fec70ebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The : The\n",
      "sun : sun\n",
      "dipped : dipped\n",
      "below : below\n",
      "the : the\n",
      "horizon : horizon\n",
      ", : ,\n",
      "casting : casting\n",
      "a : a\n",
      "golden : golden\n",
      "hue : hue\n",
      "across : across\n",
      "the : the\n",
      "silent : silent\n",
      "valley : valley\n",
      ". : .\n",
      "A : A\n",
      "gentle : gentle\n",
      "breeze : breeze\n",
      "rustled : rustled\n",
      "the : the\n",
      "tall : tall\n",
      "grass : grass\n",
      ", : ,\n",
      "whispering : whispering\n",
      "secrets : secret\n",
      "of : of\n",
      "the : the\n",
      "day : day\n",
      "gone : gone\n",
      "by : by\n",
      ". : .\n",
      "In : In\n",
      "the : the\n",
      "distance : distance\n",
      ", : ,\n",
      "an : an\n",
      "owl : owl\n",
      "hooted : hooted\n",
      ", : ,\n",
      "its : it\n",
      "call : call\n",
      "echoing : echoing\n",
      "through : through\n",
      "the : the\n",
      "twilight : twilight\n",
      ". : .\n",
      "Beneath : Beneath\n",
      "the : the\n",
      "fading : fading\n",
      "sky : sky\n",
      ", : ,\n",
      "a : a\n",
      "fox : fox\n",
      "trotted : trotted\n",
      "along : along\n",
      "a : a\n",
      "narrow : narrow\n",
      "path : path\n",
      ", : ,\n",
      "pausing : pausing\n",
      "briefly : briefly\n",
      "to : to\n",
      "sniff : sniff\n",
      "the : the\n",
      "air : air\n",
      "before : before\n",
      "disappearing : disappearing\n",
      "into : into\n",
      "the : the\n",
      "woods : wood\n",
      ". : .\n",
      "Time : Time\n",
      "seemed : seemed\n",
      "to : to\n",
      "slow : slow\n",
      ", : ,\n",
      "holding : holding\n",
      "its : it\n",
      "breath : breath\n",
      "as : a\n",
      "night : night\n",
      "unfolded : unfolded\n",
      "its : it\n",
      "velvet : velvet\n",
      "canopy : canopy\n",
      "overhead : overhead\n",
      ". : .\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "for word in Words:\n",
    "    print(f\"{word} : {lemmatizer.lemmatize(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1ffb94e-b5cb-4a4d-be99-267110c1838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d21d66f-1046-4933-962c-870bcf7a6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39b2f5a4-fc6d-421f-8599-fbdf9dfe74dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The sun dipped below the horizon, casting a golden hue across the silent valley.A gentle breeze rustled the tall grass, whispering secrets of the day gone by.In the distance, an owl hooted, its call echoing through the twilight.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = sentence[:3]\n",
    "new_sentence = [''.join(sentence)]\n",
    "new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "634096d4-f56e-4840-b4aa-cb3a6827c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tfidf(document):\n",
    "    tokenizer = TfidfVectorizer()\n",
    "    tf_matrix = tokenizer.fit_transform(document)\n",
    "    feature_names = tokenizer.get_feature_names_out()\n",
    "    return tf_matrix, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0612d065-1999-4e78-9608-6822e106f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf73f3bd-73c8-4302-a952-8c3306e47294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['across', 'an', 'below', 'breeze', 'by', 'call', 'casting', 'day',\n",
       "        'dipped', 'distance', 'echoing', 'gentle', 'golden', 'gone',\n",
       "        'grass', 'hooted', 'horizon', 'hue', 'in', 'its', 'of', 'owl',\n",
       "        'rustled', 'secrets', 'silent', 'sun', 'tall', 'the', 'through',\n",
       "        'twilight', 'valley', 'whispering'], dtype=object),\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 32 stored elements and shape (1, 32)>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix, feature_names = calculate_tfidf(new_sentence)\n",
    "print('TFIDF')\n",
    "feature_names, tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b64c21-e80f-48b4-b9fb-46a5a380b1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
